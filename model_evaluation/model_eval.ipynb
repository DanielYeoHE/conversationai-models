{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import getpass\n",
    "from IPython.display import display\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pkg_resources\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.lib.io import file_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_export.dataset import Dataset, Model\n",
    "from utils_export import utils_cloudml\n",
    "from utils_export import utils_tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GCS_READ_CACHE_MAX_SIZE_MB'] = '0' #Faster to access GCS file + https://github.com/tensorflow/tensorflow/issues/15530"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/msushkov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User inputs\n",
    "PROJECT_NAME = 'wikidetox'\n",
    "\n",
    "# Information about deployed model.\n",
    "MODEL_NAMES = [\n",
    "    'tf_gru_attention_msushkov_tuning1:v_20181216_worst',\n",
    "    'tf_gru_attention_msushkov_tuning1:tf_gru_attention_toxicity_msushkov_tuning1_medium',\n",
    "    'tf_gru_attention_msushkov_tuning1:tf_gru_attention_toxicity_msushkov_tuning1_best'\n",
    "]\n",
    "\n",
    "# Model description\n",
    "TEXT_FEATURE_NAME = 'tokens' #Input text\n",
    "SENTENCE_KEY = 'comment_key' #Input key\n",
    "LABEL_NAME_PREDICTION_MODEL = 'frac_neg/logistic' # Output prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text, lowercase=True):\n",
    "  \"\"\"Converts text to a list of words.\n",
    "\n",
    "  Args:\n",
    "    text: piece of text to tokenize (string).\n",
    "    lowercase: whether to include lowercasing in preprocessing (boolean).\n",
    "    tokenizer: Python function to tokenize the text on.\n",
    "\n",
    "  Returns:\n",
    "    A list of strings (words).\n",
    "  \"\"\"\n",
    "  words = nltk.word_tokenize(text.decode('utf-8'))\n",
    "  if lowercase:\n",
    "    words = [w.lower() for w in words]\n",
    "  return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User inputs\n",
    "TOXICITY_PERFORMANCE_DATASET = 'gs://kaggle-model-experiments/resources/toxicity_q42017_validate.tfrecord'\n",
    "TOXICITY_DATA_LABEL = 'frac_neg' #Name of the label in the performance dataset\n",
    "\n",
    "# DECODING\n",
    "decoding_input_features = {\n",
    "  TEXT_FEATURE_NAME: tf.FixedLenFeature([], dtype=tf.string),\n",
    "  TOXICITY_DATA_LABEL: tf.FixedLenFeature([], dtype=tf.float32)\n",
    "}\n",
    "\n",
    "def input_fn_performance_toxicity(max_n_examples=None, random_filter_keep_rate=1.0):\n",
    "    res = utils_tfrecords.decode_tf_records_to_pandas(\n",
    "        decoding_input_features,\n",
    "        TOXICITY_PERFORMANCE_DATASET,\n",
    "        max_n_examples,\n",
    "        random_filter_keep_rate)\n",
    "    res[TEXT_FEATURE_NAME] = list(map(tokenizer, res[TEXT_FEATURE_NAME]))\n",
    "    res = res.rename(columns={\n",
    "        TOXICITY_DATA_LABEL: 'label'})\n",
    "    res['label'] = list(map(lambda x: bool(round(x)), list(res['label'])))\n",
    "    final = res.copy(deep=True)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User inputs.\n",
    "model_input_spec = {\n",
    "    TEXT_FEATURE_NAME: utils_tfrecords.EncodingFeatureSpec.LIST_STRING\n",
    "} #library will use this automatically\n",
    "\n",
    "model = Model(\n",
    "    feature_keys_spec=model_input_spec,\n",
    "    prediction_keys=LABEL_NAME_PREDICTION_MODEL,\n",
    "    example_key=SENTENCE_KEY,\n",
    "    model_names=MODEL_NAMES,\n",
    "    project_name=PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Feature: tokens (data type: string) is required but could not be found.\n\t [[Node: ParseSingleExample_16/ParseSingleExample = ParseSingleExample[Tdense=[DT_FLOAT, DT_STRING], dense_keys=[\"frac_neg\", \"tokens\"], dense_shapes=[[], []], num_sparse=0, sparse_keys=[], sparse_types=[], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ReaderReadV2_16:1, ParseSingleExample_16/Const, ParseSingleExample_16/Const_1)]]\n\nCaused by op 'ParseSingleExample_16/ParseSingleExample', defined at:\n  File \"/Users/msushkov/homebrew/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/msushkov/homebrew/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/msushkov/homebrew/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/Users/msushkov/homebrew/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/Users/msushkov/homebrew/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n    yield self.process_one()\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n    self.run()\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-159-a4927c639ab2>\", line 1, in <module>\n    dataset_performance = Dataset(input_fn_performance_toxicity, TOXICITY_PERFORMANCE_DATASET)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/utils_export/dataset.py\", line 129, in __init__\n    self.check_input_fn(input_fn)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/utils_export/dataset.py\", line 146, in check_input_fn\n    loaded_data = input_fn(max_n_examples=1)\n  File \"<ipython-input-157-5f9269250681>\", line 16, in input_fn_performance_toxicity\n    random_filter_keep_rate)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/utils_export/utils_tfrecords.py\", line 144, in decode_tf_records_to_pandas\n    features=decoding_features_spec\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tensorflow/python/ops/parsing_ops.py\", line 758, in parse_single_example\n    return parse_single_example_v2(serialized, features, name)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tensorflow/python/ops/parsing_ops.py\", line 1282, in parse_single_example_v2\n    dense_defaults, dense_shapes, name)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tensorflow/python/ops/parsing_ops.py\", line 1399, in _parse_single_example_v2_raw\n    name=name)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tensorflow/python/ops/gen_parsing_ops.py\", line 601, in parse_single_example\n    sparse_types=sparse_types, dense_shapes=dense_shapes, name=name)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Feature: tokens (data type: string) is required but could not be found.\n\t [[Node: ParseSingleExample_16/ParseSingleExample = ParseSingleExample[Tdense=[DT_FLOAT, DT_STRING], dense_keys=[\"frac_neg\", \"tokens\"], dense_shapes=[[], []], num_sparse=0, sparse_keys=[], sparse_types=[], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ReaderReadV2_16:1, ParseSingleExample_16/Const, ParseSingleExample_16/Const_1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Feature: tokens (data type: string) is required but could not be found.\n\t [[Node: ParseSingleExample_16/ParseSingleExample = ParseSingleExample[Tdense=[DT_FLOAT, DT_STRING], dense_keys=[\"frac_neg\", \"tokens\"], dense_shapes=[[], []], num_sparse=0, sparse_keys=[], sparse_types=[], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ReaderReadV2_16:1, ParseSingleExample_16/Const, ParseSingleExample_16/Const_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-a4927c639ab2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset_performance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn_performance_toxicity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTOXICITY_PERFORMANCE_DATASET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2018\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Need to set seed before loading data to be able to reload same data in the future\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#dataset_performance.load_data(186997)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset_performance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/conversationai-models/model_evaluation/utils_export/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_fn, dataset_dir)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mtf_records\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0mof\u001b[0m \u001b[0mCMLE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/conversationai-models/model_evaluation/utils_export/dataset.py\u001b[0m in \u001b[0;36mcheck_input_fn\u001b[0;34m(self, input_fn)\u001b[0m\n\u001b[1;32m    144\u001b[0m                        ' as arguments.')\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mloaded_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_n_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-157-5f9269250681>\u001b[0m in \u001b[0;36minput_fn_performance_toxicity\u001b[0;34m(max_n_examples, random_filter_keep_rate)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mTOXICITY_PERFORMANCE_DATASET\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mmax_n_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         random_filter_keep_rate)\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTEXT_FEATURE_NAME\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTEXT_FEATURE_NAME\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     res = res.rename(columns={\n",
      "\u001b[0;32m~/code/conversationai-models/model_evaluation/utils_export/utils_tfrecords.py\u001b[0m in \u001b[0;36mdecode_tf_records_to_pandas\u001b[0;34m(decoding_features_spec, tf_records_path, max_n_examples, random_filter_keep_rate, filter_fn)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m   \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m   \u001b[0mnew_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m   \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mnew_line\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Feature: tokens (data type: string) is required but could not be found.\n\t [[Node: ParseSingleExample_16/ParseSingleExample = ParseSingleExample[Tdense=[DT_FLOAT, DT_STRING], dense_keys=[\"frac_neg\", \"tokens\"], dense_shapes=[[], []], num_sparse=0, sparse_keys=[], sparse_types=[], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ReaderReadV2_16:1, ParseSingleExample_16/Const, ParseSingleExample_16/Const_1)]]\n\nCaused by op 'ParseSingleExample_16/ParseSingleExample', defined at:\n  File \"/Users/msushkov/homebrew/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/msushkov/homebrew/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/msushkov/homebrew/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/Users/msushkov/homebrew/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/Users/msushkov/homebrew/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 370, in dispatch_queue\n    yield self.process_one()\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\n    self.run()\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-159-a4927c639ab2>\", line 1, in <module>\n    dataset_performance = Dataset(input_fn_performance_toxicity, TOXICITY_PERFORMANCE_DATASET)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/utils_export/dataset.py\", line 129, in __init__\n    self.check_input_fn(input_fn)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/utils_export/dataset.py\", line 146, in check_input_fn\n    loaded_data = input_fn(max_n_examples=1)\n  File \"<ipython-input-157-5f9269250681>\", line 16, in input_fn_performance_toxicity\n    random_filter_keep_rate)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/utils_export/utils_tfrecords.py\", line 144, in decode_tf_records_to_pandas\n    features=decoding_features_spec\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tensorflow/python/ops/parsing_ops.py\", line 758, in parse_single_example\n    return parse_single_example_v2(serialized, features, name)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tensorflow/python/ops/parsing_ops.py\", line 1282, in parse_single_example_v2\n    dense_defaults, dense_shapes, name)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tensorflow/python/ops/parsing_ops.py\", line 1399, in _parse_single_example_v2_raw\n    name=name)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tensorflow/python/ops/gen_parsing_ops.py\", line 601, in parse_single_example\n    sparse_types=sparse_types, dense_shapes=dense_shapes, name=name)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/Users/msushkov/code/conversationai-models/model_evaluation/.pyenv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Feature: tokens (data type: string) is required but could not be found.\n\t [[Node: ParseSingleExample_16/ParseSingleExample = ParseSingleExample[Tdense=[DT_FLOAT, DT_STRING], dense_keys=[\"frac_neg\", \"tokens\"], dense_shapes=[[], []], num_sparse=0, sparse_keys=[], sparse_types=[], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ReaderReadV2_16:1, ParseSingleExample_16/Const, ParseSingleExample_16/Const_1)]]\n"
     ]
    }
   ],
   "source": [
    "dataset_performance = Dataset(input_fn_performance_toxicity, TOXICITY_PERFORMANCE_DATASET)\n",
    "random.seed(2018) # Need to set seed before loading data to be able to reload same data in the future\n",
    "#dataset_performance.load_data(186997)\n",
    "dataset_performance.load_data(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set recompute_predictions=False to save time if predictions are available.\n",
    "dataset_performance.add_model_prediction_to_data(model, recompute_predictions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
