{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from IPython.display import display\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read scored test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_data_path = 'gs://conversationai-models/biosbias/scored_data/test_standard_0409.csv'\n",
    "scrubbed_data_path = 'gs://conversationai-models/biosbias/scored_data/test_scrubbed_0409_old.csv'\n",
    "very_scrubbed_data_path = 'gs://conversationai-models/biosbias/scored_data/test_very_scrubbed_0409_old.csv'\n",
    "gender_data_path = 'gs://conversationai-models/biosbias/scored_data/test_data_gender.csv'\n",
    "\n",
    "\n",
    "perf_df = pd.read_csv(tf.gfile.Open(standard_data_path)).drop_duplicates(subset=['tokens'])\n",
    "scrubbed_df = pd.read_csv(tf.gfile.Open(scrubbed_data_path)).drop_duplicates(subset=['tokens'])\n",
    "very_scrubbed_df = pd.read_csv(tf.gfile.Open(very_scrubbed_data_path)).drop_duplicates(subset=['tokens'])\n",
    "gender_df = pd.read_csv(tf.gfile.Open(gender_data_path)).drop_duplicates(subset=['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59824, 300)\n",
      "(59820, 36)\n"
     ]
    }
   ],
   "source": [
    "print(perf_df.shape)\n",
    "print(scrubbed_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = perf_df.join(scrubbed_df, rsuffix = '_scrubbed')\n",
    "df = df.join(very_scrubbed_df, rsuffix = '_very_scrubbed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>gender</th>\n",
       "      <th>label</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190328_103117_0</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190328_103117_1</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190328_103117_2</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190328_103117_3</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190328_103117_4</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190328_103117_5</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190328_103117_6</th>\n",
       "      <th>...</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175254_23</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175254_24</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175254_25</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175254_26</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175254_27</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175254_28</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175254_29</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175254_30</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175254_31</th>\n",
       "      <th>tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175254_32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[u'he', u'is', u'currently', u'working', u'clo...</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>4.625991e-14</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>2.642943e-04</td>\n",
       "      <td>1.613340e-07</td>\n",
       "      <td>4.687537e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001929</td>\n",
       "      <td>1.914383e-06</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>7.086468e-07</td>\n",
       "      <td>8.798547e-16</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>8.315536e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[u'she', u'has', u'a', u'passion', u'for', u'w...</td>\n",
       "      <td>F</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>5.970340e-18</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>8.439872e-06</td>\n",
       "      <td>1.380430e-07</td>\n",
       "      <td>8.653511e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013356</td>\n",
       "      <td>7.866625e-01</td>\n",
       "      <td>0.009269</td>\n",
       "      <td>0.024264</td>\n",
       "      <td>3.710595e-04</td>\n",
       "      <td>2.425320e-11</td>\n",
       "      <td>0.004488</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.032467</td>\n",
       "      <td>1.274749e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[u'growing', u'up', u'under', u'the', u'influe...</td>\n",
       "      <td>M</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>1.023775e-15</td>\n",
       "      <td>0.008020</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>1.159827e-06</td>\n",
       "      <td>2.420847e-06</td>\n",
       "      <td>4.043094e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>8.046401e-04</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>3.003297e-05</td>\n",
       "      <td>8.979249e-14</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>4.318769e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[u'he', u'earned', u'his', u'beng', u'degree',...</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.354895e-13</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>1.071294e-07</td>\n",
       "      <td>1.333064e-08</td>\n",
       "      <td>1.857020e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009217</td>\n",
       "      <td>1.700057e-02</td>\n",
       "      <td>0.136035</td>\n",
       "      <td>0.009581</td>\n",
       "      <td>2.460610e-03</td>\n",
       "      <td>1.396903e-09</td>\n",
       "      <td>0.002276</td>\n",
       "      <td>0.009811</td>\n",
       "      <td>0.026841</td>\n",
       "      <td>1.840305e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[u'her', u'professional', u'and', u'educationa...</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>6.887217e-12</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.021189</td>\n",
       "      <td>1.852501e-03</td>\n",
       "      <td>6.723991e-05</td>\n",
       "      <td>7.880444e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>9.174340e-08</td>\n",
       "      <td>0.995151</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>9.952086e-11</td>\n",
       "      <td>4.422046e-14</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>1.483144e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 372 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens gender  label  \\\n",
       "0  [u'he', u'is', u'currently', u'working', u'clo...      M     25   \n",
       "1  [u'she', u'has', u'a', u'passion', u'for', u'w...      F     26   \n",
       "2  [u'growing', u'up', u'under', u'the', u'influe...      M     22   \n",
       "3  [u'he', u'earned', u'his', u'beng', u'degree',...      M     25   \n",
       "4  [u'her', u'professional', u'and', u'educationa...      F     25   \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190328_103117_0  \\\n",
       "0                                           0.000008                           \n",
       "1                                           0.000001                           \n",
       "2                                           0.000205                           \n",
       "3                                           0.000009                           \n",
       "4                                           0.001034                           \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190328_103117_1  \\\n",
       "0                                       4.625991e-14                           \n",
       "1                                       5.970340e-18                           \n",
       "2                                       1.023775e-15                           \n",
       "3                                       1.354895e-13                           \n",
       "4                                       6.887217e-12                           \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190328_103117_2  \\\n",
       "0                                           0.000089                           \n",
       "1                                           0.000004                           \n",
       "2                                           0.008020                           \n",
       "3                                           0.001508                           \n",
       "4                                           0.000701                           \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190328_103117_3  \\\n",
       "0                                           0.000432                           \n",
       "1                                           0.000155                           \n",
       "2                                           0.000054                           \n",
       "3                                           0.000051                           \n",
       "4                                           0.021189                           \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190328_103117_4  \\\n",
       "0                                       2.642943e-04                           \n",
       "1                                       8.439872e-06                           \n",
       "2                                       1.159827e-06                           \n",
       "3                                       1.071294e-07                           \n",
       "4                                       1.852501e-03                           \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190328_103117_5  \\\n",
       "0                                       1.613340e-07                           \n",
       "1                                       1.380430e-07                           \n",
       "2                                       2.420847e-06                           \n",
       "3                                       1.333064e-08                           \n",
       "4                                       6.723991e-05                           \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190328_103117_6  \\\n",
       "0                                       4.687537e-07                           \n",
       "1                                       8.653511e-09                           \n",
       "2                                       4.043094e-06                           \n",
       "3                                       1.857020e-05                           \n",
       "4                                       7.880444e-06                           \n",
       "\n",
       "                                      ...                                      \\\n",
       "0                                     ...                                       \n",
       "1                                     ...                                       \n",
       "2                                     ...                                       \n",
       "3                                     ...                                       \n",
       "4                                     ...                                       \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175254_23  \\\n",
       "0                                           0.001929                            \n",
       "1                                           0.013356                            \n",
       "2                                           0.000135                            \n",
       "3                                           0.009217                            \n",
       "4                                           0.000425                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175254_24  \\\n",
       "0                                       1.914383e-06                            \n",
       "1                                       7.866625e-01                            \n",
       "2                                       8.046401e-04                            \n",
       "3                                       1.700057e-02                            \n",
       "4                                       9.174340e-08                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175254_25  \\\n",
       "0                                           0.000097                            \n",
       "1                                           0.009269                            \n",
       "2                                           0.002173                            \n",
       "3                                           0.136035                            \n",
       "4                                           0.995151                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175254_26  \\\n",
       "0                                           0.000332                            \n",
       "1                                           0.024264                            \n",
       "2                                           0.000697                            \n",
       "3                                           0.009581                            \n",
       "4                                           0.001635                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175254_27  \\\n",
       "0                                       7.086468e-07                            \n",
       "1                                       3.710595e-04                            \n",
       "2                                       3.003297e-05                            \n",
       "3                                       2.460610e-03                            \n",
       "4                                       9.952086e-11                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175254_28  \\\n",
       "0                                       8.798547e-16                            \n",
       "1                                       2.425320e-11                            \n",
       "2                                       8.979249e-14                            \n",
       "3                                       1.396903e-09                            \n",
       "4                                       4.422046e-14                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175254_29  \\\n",
       "0                                           0.000041                            \n",
       "1                                           0.004488                            \n",
       "2                                           0.001901                            \n",
       "3                                           0.002276                            \n",
       "4                                           0.000974                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175254_30  \\\n",
       "0                                           0.000395                            \n",
       "1                                           0.002426                            \n",
       "2                                           0.000097                            \n",
       "3                                           0.009811                            \n",
       "4                                           0.000039                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175254_31  \\\n",
       "0                                           0.000054                            \n",
       "1                                           0.032467                            \n",
       "2                                           0.001727                            \n",
       "3                                           0.026841                            \n",
       "4                                           0.000482                            \n",
       "\n",
       "   tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175254_32  \n",
       "0                                       8.315536e-08                           \n",
       "1                                       1.274749e-04                           \n",
       "2                                       4.318769e-06                           \n",
       "3                                       1.840305e-04                           \n",
       "4                                       1.483144e-07                           \n",
       "\n",
       "[5 rows x 372 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59824, 372)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59753, 372)\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_from_col_name(col_name):\n",
    "    #print(col_name)\n",
    "    pattern = r'^.*_(\\d+)$'\n",
    "    return int(re.search(pattern, col_name).group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_class(df, model_name, class_names):\n",
    "    model_class_names = ['{}_{}'.format(model_name, class_name) for class_name in class_names]\n",
    "    sub_df = df[model_class_names]\n",
    "    df['{}_class'.format(model_name)] = sub_df.idxmax(axis=1).apply(get_class_from_col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can check model names here\n",
    "# df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May have to change.\n",
    "# Can look them up in experiment tracker.\n",
    "MODEL_NAMES = {\n",
    "    'tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_174837': 'debiased_tolga',\n",
    "    'tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_174941': 'debiased_biosbias',\n",
    "    'tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175003': 'strong_debiased_1',\n",
    "    'tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175019': 'strong_debiased_2',\n",
    "    'tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175034': 'strong_debiased_3',\n",
    "    'tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175055': 'strong_debiased_4',\n",
    "    'tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190328_103117': 'glove',\n",
    "    'tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175113': 'strong_no_equalize',\n",
    "    'tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175131': 'strong_no_projection', \n",
    "    'tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190315_112954': 'scrubbed',\n",
    "    'tf_trainer_tf_gru_attention_multiclass_biosbias_glove:v_20190410_175254': 'very_scrubbed'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = range(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _model in MODEL_NAMES:\n",
    "    find_best_class(df, _model, CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels with either gender having too few examples\n",
    "bad_labels = df.groupby('label').gender.value_counts().reset_index(name = 'count').query('count < 5').label.values\n",
    "#assert len(bad_labels) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label  gender\n",
       "0      M          526\n",
       "       F          315\n",
       "2      M         1165\n",
       "       F          339\n",
       "3      M         3136\n",
       "       F         1819\n",
       "4      M          298\n",
       "       F          127\n",
       "5      M          345\n",
       "       F           97\n",
       "6      M          691\n",
       "       F          125\n",
       "7      M         1449\n",
       "       F          766\n",
       "8      F          590\n",
       "       M           51\n",
       "9      M          200\n",
       "       F           34\n",
       "10     M          707\n",
       "       F          336\n",
       "11     F          162\n",
       "       M           45\n",
       "12     M         1553\n",
       "       F         1505\n",
       "16     F          923\n",
       "       M          204\n",
       "17     F         2535\n",
       "       M          237\n",
       "18     M          661\n",
       "       F          546\n",
       "19     F          207\n",
       "       M           32\n",
       "20     M          279\n",
       "       F           83\n",
       "21     M          109\n",
       "       F           96\n",
       "22     M         2344\n",
       "       F         1301\n",
       "23     M         3152\n",
       "       F         3043\n",
       "24     M          549\n",
       "       F          513\n",
       "25     M         9686\n",
       "       F         8003\n",
       "26     F         1735\n",
       "       M         1060\n",
       "27     M          181\n",
       "       F           17\n",
       "29     M          897\n",
       "       F          168\n",
       "30     M         1791\n",
       "       F          325\n",
       "31     F         1462\n",
       "       M          957\n",
       "32     F          237\n",
       "       M           39\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').gender.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for model debiased_biosbias: 0.806972034877\n",
      "Accuracy for model very_scrubbed: 0.355915184175\n",
      "Accuracy for model debiased_tolga: 0.818921225713\n",
      "Accuracy for model strong_debiased_1: 0.817984034274\n",
      "Accuracy for model strong_no_projection: 0.806687530333\n",
      "Accuracy for model strong_debiased_2: 0.81733134738\n",
      "Accuracy for model strong_no_equalize: 0.815239402206\n",
      "Accuracy for model glove: 0.817950563152\n",
      "Accuracy for model strong_debiased_4: 0.814737335364\n",
      "Accuracy for model strong_debiased_3: 0.817599116362\n",
      "Accuracy for model scrubbed: 0.130503907754\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "for _model in MODEL_NAMES:\n",
    "    is_correct = (df['{}_class'.format(_model)] == df['label'])\n",
    "    _acc = sum(is_correct)/len(is_correct)\n",
    "    accuracy_list.append(_acc)\n",
    "    print ('Accuracy for model {}: {}'.format(MODEL_NAMES[_model], _acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _class in CLASS_NAMES:\n",
    "    df['label_{}'.format(_class)] = (df['label'] == _class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender ratios of classes\n",
    "gender_counts = df.groupby('label').gender.value_counts().reset_index(name = 'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frac_female(df):\n",
    "    m_count = df[df['gender'] == \"M\"]['count'].values[0]\n",
    "    f_count = df[df['gender'] == \"F\"]['count'].values[0]\n",
    "    return {'label': df['label'].values[0], 'frac_female': f_count/(m_count+f_count)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_female_df = pd.DataFrame(list(gender_counts.groupby('label', as_index = False).apply(frac_female)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tpr(df, _class, _model, threshold = 0.5):\n",
    "    tpr = metrics.recall_score(df['label_{}'.format(_class)],\n",
    "                               df['{}_{}'.format(_model,_class)] > threshold)\n",
    "    return tpr\n",
    "    \n",
    "def compute_tpr_by_gender(df, _class, _model, threshold = 0.5):\n",
    "    tpr_m = compute_tpr(df.query('gender == \"M\"'), _class, _model, threshold)\n",
    "    tpr_f = compute_tpr(df.query('gender == \"F\"'), _class, _model, threshold)\n",
    "    return {'M': tpr_m, 'F': tpr_f}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Just add precision here for precision for each class and by gender\n",
    "# TODO: Also just overall per gender PR and per gender TPR, TNR\n",
    "def compute_tpr_tnr(df, _class, _model, threshold = 0.5):\n",
    "    #cm = metrics.confusion_matrix(df['label_{}'.format(_class)],\n",
    "    #                              df['{}_{}'.format(_model,_class)] > threshold)\n",
    "    cm = pd.crosstab(df['label_{}'.format(_class)], df['{}_{}'.format(_model,_class)] > threshold)\n",
    "    #display(cm)\n",
    "    if cm.shape[0] > 1:\n",
    "        tn = cm.iloc[0,0]\n",
    "        fp = cm.iloc[0,1]\n",
    "        fn = cm.iloc[1,0]\n",
    "        tp = cm.iloc[1,1]\n",
    "        tpr = tp/(tp+fn)\n",
    "        tnr = tn/(tn+fp)\n",
    "    else:\n",
    "        tpr = 0\n",
    "        tnr = 1\n",
    "    return tpr, tnr\n",
    "\n",
    "def compute_tr_by_gender(df, _class, _model, threshold = 0.5):\n",
    "    tpr_m, tnr_m = compute_tpr_tnr(df.query('gender == \"M\"'), _class, _model, threshold)\n",
    "    tpr_f, tnr_f = compute_tpr_tnr(df.query('gender == \"F\"'), _class, _model, threshold)\n",
    "    return {'TPR_m': tpr_m, 'TPR_f': tpr_f, 'TNR_m': tnr_m, 'TNR_f': tnr_f}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _class in CLASS_NAMES:\n",
    "    for _model in MODEL_NAMES:\n",
    "        tpr_1 = compute_tpr(df, _class, _model)\n",
    "        tpr_2, _ = compute_tpr_tnr(df, _class, _model)\n",
    "        assert tpr_1 == tpr_2, '{} != {}'.format(tpr_1, tpr_2)\n",
    "        #print('{} == {}'.format(tpr_1, tpr_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_df = pd.DataFrame()\n",
    "for _class in frac_female_df.label:\n",
    "    row = {}\n",
    "    row['label'] = _class\n",
    "    for _model, _model_type in MODEL_NAMES.items():\n",
    "        tpr, tnr = compute_tpr_tnr(df, _class, _model)\n",
    "        row['{}_tpr'.format(_model_type)] = tpr\n",
    "        row['{}_tnr'.format(_model_type)] = tnr\n",
    "        gender_trs = compute_tr_by_gender(df, _class, _model)\n",
    "        row['{}_tpr_F'.format(_model_type)] = gender_trs['TPR_f']\n",
    "        row['{}_tpr_M'.format(_model_type)] = gender_trs['TPR_m']\n",
    "        row['{}_tpr_gender_gap'.format(_model_type)] = gender_trs['TPR_f'] - gender_trs['TPR_m']\n",
    "        row['{}_tnr_F'.format(_model_type)] = gender_trs['TNR_f']\n",
    "        row['{}_tnr_M'.format(_model_type)] = gender_trs['TNR_m']\n",
    "        row['{}_tnr_gender_gap'.format(_model_type)] = gender_trs['TNR_f'] - gender_trs['TNR_m']\n",
    "    tpr_df = tpr_df.append(row, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.merge(tpr_df, frac_female_df, on = 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLE_LABELS = [\n",
    "    'accountant', 'acupuncturist', 'architect', 'attorney', 'chiropractor', 'comedian', 'composer', 'dentist',\n",
    "    'dietitian', 'dj', 'filmmaker', 'interior_designer', 'journalist', 'landscape_architect', 'magician',\n",
    "    'massage_therapist', 'model', 'nurse', 'painter', 'paralegal', 'pastor', 'personal_trainer',\n",
    "    'photographer', 'physician', 'poet', 'professor', 'psychologist', 'rapper',\n",
    "    'real_estate_broker', 'software_engineer', 'surgeon', 'teacher', 'yoga_teacher']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['label_profession'] = results_df['label'].apply(lambda x: TITLE_LABELS[int(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>debiased_biosbias_tnr</th>\n",
       "      <th>debiased_biosbias_tnr_F</th>\n",
       "      <th>debiased_biosbias_tnr_M</th>\n",
       "      <th>debiased_biosbias_tnr_gender_gap</th>\n",
       "      <th>debiased_biosbias_tpr</th>\n",
       "      <th>debiased_biosbias_tpr_F</th>\n",
       "      <th>debiased_biosbias_tpr_M</th>\n",
       "      <th>debiased_biosbias_tpr_gender_gap</th>\n",
       "      <th>debiased_tolga_tnr</th>\n",
       "      <th>debiased_tolga_tnr_F</th>\n",
       "      <th>...</th>\n",
       "      <th>very_scrubbed_tnr</th>\n",
       "      <th>very_scrubbed_tnr_F</th>\n",
       "      <th>very_scrubbed_tnr_M</th>\n",
       "      <th>very_scrubbed_tnr_gender_gap</th>\n",
       "      <th>very_scrubbed_tpr</th>\n",
       "      <th>very_scrubbed_tpr_F</th>\n",
       "      <th>very_scrubbed_tpr_M</th>\n",
       "      <th>very_scrubbed_tpr_gender_gap</th>\n",
       "      <th>frac_female</th>\n",
       "      <th>label_profession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999474</td>\n",
       "      <td>0.999668</td>\n",
       "      <td>0.999309</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.615933</td>\n",
       "      <td>0.580952</td>\n",
       "      <td>0.636882</td>\n",
       "      <td>-0.055930</td>\n",
       "      <td>0.999287</td>\n",
       "      <td>0.999336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992854</td>\n",
       "      <td>0.993578</td>\n",
       "      <td>0.992237</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.216409</td>\n",
       "      <td>0.196825</td>\n",
       "      <td>0.228137</td>\n",
       "      <td>-0.031311</td>\n",
       "      <td>0.374554</td>\n",
       "      <td>accountant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.997579</td>\n",
       "      <td>0.998559</td>\n",
       "      <td>0.996729</td>\n",
       "      <td>0.001831</td>\n",
       "      <td>0.521941</td>\n",
       "      <td>0.563422</td>\n",
       "      <td>0.509871</td>\n",
       "      <td>0.053551</td>\n",
       "      <td>0.994197</td>\n",
       "      <td>0.996528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.989699</td>\n",
       "      <td>0.989102</td>\n",
       "      <td>0.990218</td>\n",
       "      <td>-0.001115</td>\n",
       "      <td>0.156915</td>\n",
       "      <td>0.159292</td>\n",
       "      <td>0.156223</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>0.225399</td>\n",
       "      <td>architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.994160</td>\n",
       "      <td>0.994373</td>\n",
       "      <td>0.993974</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.850050</td>\n",
       "      <td>0.827378</td>\n",
       "      <td>0.863202</td>\n",
       "      <td>-0.035824</td>\n",
       "      <td>0.993649</td>\n",
       "      <td>0.993318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944451</td>\n",
       "      <td>0.946229</td>\n",
       "      <td>0.942892</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>0.335621</td>\n",
       "      <td>0.333150</td>\n",
       "      <td>0.337054</td>\n",
       "      <td>-0.003903</td>\n",
       "      <td>0.367104</td>\n",
       "      <td>attorney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.998803</td>\n",
       "      <td>0.999230</td>\n",
       "      <td>0.998440</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.622047</td>\n",
       "      <td>0.647651</td>\n",
       "      <td>-0.025604</td>\n",
       "      <td>0.998770</td>\n",
       "      <td>0.999267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.993814</td>\n",
       "      <td>0.993732</td>\n",
       "      <td>0.993884</td>\n",
       "      <td>-0.000152</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.220472</td>\n",
       "      <td>0.224832</td>\n",
       "      <td>-0.004360</td>\n",
       "      <td>0.298824</td>\n",
       "      <td>chiropractor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999815</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.999719</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.547511</td>\n",
       "      <td>0.371134</td>\n",
       "      <td>0.597101</td>\n",
       "      <td>-0.225967</td>\n",
       "      <td>0.999460</td>\n",
       "      <td>0.999780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996139</td>\n",
       "      <td>0.996265</td>\n",
       "      <td>0.996031</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.208145</td>\n",
       "      <td>0.144330</td>\n",
       "      <td>0.226087</td>\n",
       "      <td>-0.081757</td>\n",
       "      <td>0.219457</td>\n",
       "      <td>comedian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   debiased_biosbias_tnr  debiased_biosbias_tnr_F  debiased_biosbias_tnr_M  \\\n",
       "0               0.999474                 0.999668                 0.999309   \n",
       "1               0.997579                 0.998559                 0.996729   \n",
       "2               0.994160                 0.994373                 0.993974   \n",
       "3               0.998803                 0.999230                 0.998440   \n",
       "4               0.999815                 0.999927                 0.999719   \n",
       "\n",
       "   debiased_biosbias_tnr_gender_gap  debiased_biosbias_tpr  \\\n",
       "0                          0.000359               0.615933   \n",
       "1                          0.001831               0.521941   \n",
       "2                          0.000399               0.850050   \n",
       "3                          0.000791               0.640000   \n",
       "4                          0.000208               0.547511   \n",
       "\n",
       "   debiased_biosbias_tpr_F  debiased_biosbias_tpr_M  \\\n",
       "0                 0.580952                 0.636882   \n",
       "1                 0.563422                 0.509871   \n",
       "2                 0.827378                 0.863202   \n",
       "3                 0.622047                 0.647651   \n",
       "4                 0.371134                 0.597101   \n",
       "\n",
       "   debiased_biosbias_tpr_gender_gap  debiased_tolga_tnr  debiased_tolga_tnr_F  \\\n",
       "0                         -0.055930            0.999287              0.999336   \n",
       "1                          0.053551            0.994197              0.996528   \n",
       "2                         -0.035824            0.993649              0.993318   \n",
       "3                         -0.025604            0.998770              0.999267   \n",
       "4                         -0.225967            0.999460              0.999780   \n",
       "\n",
       "         ...         very_scrubbed_tnr  very_scrubbed_tnr_F  \\\n",
       "0        ...                  0.992854             0.993578   \n",
       "1        ...                  0.989699             0.989102   \n",
       "2        ...                  0.944451             0.946229   \n",
       "3        ...                  0.993814             0.993732   \n",
       "4        ...                  0.996139             0.996265   \n",
       "\n",
       "   very_scrubbed_tnr_M  very_scrubbed_tnr_gender_gap  very_scrubbed_tpr  \\\n",
       "0             0.992237                      0.001341           0.216409   \n",
       "1             0.990218                     -0.001115           0.156915   \n",
       "2             0.942892                      0.003337           0.335621   \n",
       "3             0.993884                     -0.000152           0.223529   \n",
       "4             0.996031                      0.000234           0.208145   \n",
       "\n",
       "   very_scrubbed_tpr_F  very_scrubbed_tpr_M  very_scrubbed_tpr_gender_gap  \\\n",
       "0             0.196825             0.228137                     -0.031311   \n",
       "1             0.159292             0.156223                      0.003069   \n",
       "2             0.333150             0.337054                     -0.003903   \n",
       "3             0.220472             0.224832                     -0.004360   \n",
       "4             0.144330             0.226087                     -0.081757   \n",
       "\n",
       "   frac_female  label_profession  \n",
       "0     0.374554        accountant  \n",
       "1     0.225399         architect  \n",
       "2     0.367104          attorney  \n",
       "3     0.298824      chiropractor  \n",
       "4     0.219457          comedian  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frac_female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>frac_female</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debiased_biosbias_tpr_gender_gap</th>\n",
       "      <td>0.829982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>very_scrubbed_tpr_gender_gap</th>\n",
       "      <td>0.458378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debiased_tolga_tpr_gender_gap</th>\n",
       "      <td>0.824882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strong_debiased_1_tpr_gender_gap</th>\n",
       "      <td>0.716922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strong_no_projection_tpr_gender_gap</th>\n",
       "      <td>0.709000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strong_debiased_2_tpr_gender_gap</th>\n",
       "      <td>0.596896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strong_no_equalize_tpr_gender_gap</th>\n",
       "      <td>0.772645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glove_tpr_gender_gap</th>\n",
       "      <td>0.794059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strong_debiased_4_tpr_gender_gap</th>\n",
       "      <td>0.550435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strong_debiased_3_tpr_gender_gap</th>\n",
       "      <td>0.707174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scrubbed_tpr_gender_gap</th>\n",
       "      <td>-0.282919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     frac_female\n",
       "frac_female                             1.000000\n",
       "debiased_biosbias_tpr_gender_gap        0.829982\n",
       "very_scrubbed_tpr_gender_gap            0.458378\n",
       "debiased_tolga_tpr_gender_gap           0.824882\n",
       "strong_debiased_1_tpr_gender_gap        0.716922\n",
       "strong_no_projection_tpr_gender_gap     0.709000\n",
       "strong_debiased_2_tpr_gender_gap        0.596896\n",
       "strong_no_equalize_tpr_gender_gap       0.772645\n",
       "glove_tpr_gender_gap                    0.794059\n",
       "strong_debiased_4_tpr_gender_gap        0.550435\n",
       "strong_debiased_3_tpr_gender_gap        0.707174\n",
       "scrubbed_tpr_gender_gap                -0.282919"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correlation of gender gap for each model with frac_female\n",
    "results_df[['frac_female']+['{}_tpr_gender_gap'.format(_model) for _model in MODEL_NAMES.values()]].corr()[['frac_female']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_gender_gap_cols = ['{}_tpr_gender_gap'.format(_model) for _model in MODEL_NAMES.values()]\n",
    "tnr_gender_gap_cols = ['{}_tnr_gender_gap'.format(_model) for _model in MODEL_NAMES.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_gap_df = results_df[['label_profession', 'frac_female']+tpr_gender_gap_cols+tnr_gender_gap_cols]\n",
    "#gender_gap_df.columns = ['label_profession', 'frac_female']+['{}'.format(_model) for _model in MODEL_NAMES.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_profession</th>\n",
       "      <th>frac_female</th>\n",
       "      <th>debiased_biosbias_tpr_gender_gap</th>\n",
       "      <th>very_scrubbed_tpr_gender_gap</th>\n",
       "      <th>debiased_tolga_tpr_gender_gap</th>\n",
       "      <th>strong_debiased_1_tpr_gender_gap</th>\n",
       "      <th>strong_no_projection_tpr_gender_gap</th>\n",
       "      <th>strong_debiased_2_tpr_gender_gap</th>\n",
       "      <th>strong_no_equalize_tpr_gender_gap</th>\n",
       "      <th>glove_tpr_gender_gap</th>\n",
       "      <th>...</th>\n",
       "      <th>very_scrubbed_tnr_gender_gap</th>\n",
       "      <th>debiased_tolga_tnr_gender_gap</th>\n",
       "      <th>strong_debiased_1_tnr_gender_gap</th>\n",
       "      <th>strong_no_projection_tnr_gender_gap</th>\n",
       "      <th>strong_debiased_2_tnr_gender_gap</th>\n",
       "      <th>strong_no_equalize_tnr_gender_gap</th>\n",
       "      <th>glove_tnr_gender_gap</th>\n",
       "      <th>strong_debiased_4_tnr_gender_gap</th>\n",
       "      <th>strong_debiased_3_tnr_gender_gap</th>\n",
       "      <th>scrubbed_tnr_gender_gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dietitian</td>\n",
       "      <td>0.920437</td>\n",
       "      <td>0.290927</td>\n",
       "      <td>0.173878</td>\n",
       "      <td>0.297707</td>\n",
       "      <td>0.199900</td>\n",
       "      <td>0.223862</td>\n",
       "      <td>0.187072</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.232835</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000674</td>\n",
       "      <td>-0.002692</td>\n",
       "      <td>-0.001220</td>\n",
       "      <td>-0.001617</td>\n",
       "      <td>-0.001530</td>\n",
       "      <td>-0.002213</td>\n",
       "      <td>-0.002810</td>\n",
       "      <td>-0.001630</td>\n",
       "      <td>-0.001412</td>\n",
       "      <td>-0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nurse</td>\n",
       "      <td>0.914502</td>\n",
       "      <td>0.082735</td>\n",
       "      <td>0.013742</td>\n",
       "      <td>0.085377</td>\n",
       "      <td>0.048740</td>\n",
       "      <td>0.033271</td>\n",
       "      <td>0.025981</td>\n",
       "      <td>0.057404</td>\n",
       "      <td>0.082411</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001686</td>\n",
       "      <td>-0.007627</td>\n",
       "      <td>-0.007427</td>\n",
       "      <td>-0.004478</td>\n",
       "      <td>-0.004807</td>\n",
       "      <td>-0.004455</td>\n",
       "      <td>-0.005866</td>\n",
       "      <td>-0.002840</td>\n",
       "      <td>-0.002707</td>\n",
       "      <td>-0.001573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>paralegal</td>\n",
       "      <td>0.866109</td>\n",
       "      <td>0.375755</td>\n",
       "      <td>0.094656</td>\n",
       "      <td>0.317482</td>\n",
       "      <td>0.262077</td>\n",
       "      <td>0.256944</td>\n",
       "      <td>0.271437</td>\n",
       "      <td>0.314915</td>\n",
       "      <td>0.271437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>yoga_teacher</td>\n",
       "      <td>0.858696</td>\n",
       "      <td>0.276534</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>0.143784</td>\n",
       "      <td>0.208049</td>\n",
       "      <td>0.116196</td>\n",
       "      <td>0.195067</td>\n",
       "      <td>0.161636</td>\n",
       "      <td>0.208374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>-0.001455</td>\n",
       "      <td>-0.001289</td>\n",
       "      <td>-0.000758</td>\n",
       "      <td>-0.001393</td>\n",
       "      <td>-0.001211</td>\n",
       "      <td>-0.001211</td>\n",
       "      <td>-0.001081</td>\n",
       "      <td>-0.001399</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>model</td>\n",
       "      <td>0.818988</td>\n",
       "      <td>0.480652</td>\n",
       "      <td>0.176120</td>\n",
       "      <td>0.544309</td>\n",
       "      <td>0.418456</td>\n",
       "      <td>0.460211</td>\n",
       "      <td>0.455824</td>\n",
       "      <td>0.532551</td>\n",
       "      <td>0.505093</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001022</td>\n",
       "      <td>-0.000566</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.000513</td>\n",
       "      <td>-0.001008</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.001161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>interior_designer</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.182716</td>\n",
       "      <td>-0.013580</td>\n",
       "      <td>0.243210</td>\n",
       "      <td>0.081481</td>\n",
       "      <td>0.096296</td>\n",
       "      <td>0.041975</td>\n",
       "      <td>0.224691</td>\n",
       "      <td>0.270370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>-0.000884</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>-0.000676</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0.000407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>psychologist</td>\n",
       "      <td>0.620751</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.008890</td>\n",
       "      <td>0.045876</td>\n",
       "      <td>0.043524</td>\n",
       "      <td>0.045169</td>\n",
       "      <td>0.020219</td>\n",
       "      <td>0.042056</td>\n",
       "      <td>0.017593</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000742</td>\n",
       "      <td>-0.005913</td>\n",
       "      <td>-0.004535</td>\n",
       "      <td>-0.002672</td>\n",
       "      <td>-0.002096</td>\n",
       "      <td>-0.004275</td>\n",
       "      <td>-0.002278</td>\n",
       "      <td>-0.003760</td>\n",
       "      <td>-0.002820</td>\n",
       "      <td>-0.001450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>teacher</td>\n",
       "      <td>0.604382</td>\n",
       "      <td>0.111221</td>\n",
       "      <td>0.025352</td>\n",
       "      <td>0.129299</td>\n",
       "      <td>0.111760</td>\n",
       "      <td>0.113756</td>\n",
       "      <td>0.114246</td>\n",
       "      <td>0.119168</td>\n",
       "      <td>0.137121</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000813</td>\n",
       "      <td>-0.004694</td>\n",
       "      <td>-0.002497</td>\n",
       "      <td>-0.004570</td>\n",
       "      <td>-0.001141</td>\n",
       "      <td>-0.002609</td>\n",
       "      <td>-0.002664</td>\n",
       "      <td>-0.002461</td>\n",
       "      <td>-0.001785</td>\n",
       "      <td>0.000671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>journalist</td>\n",
       "      <td>0.492152</td>\n",
       "      <td>0.019865</td>\n",
       "      <td>0.010182</td>\n",
       "      <td>0.057554</td>\n",
       "      <td>0.021920</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.013070</td>\n",
       "      <td>0.042923</td>\n",
       "      <td>0.058686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>-0.000167</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>-0.002623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>physician</td>\n",
       "      <td>0.491203</td>\n",
       "      <td>0.019845</td>\n",
       "      <td>0.036850</td>\n",
       "      <td>0.056989</td>\n",
       "      <td>0.035120</td>\n",
       "      <td>0.042554</td>\n",
       "      <td>0.040719</td>\n",
       "      <td>0.034896</td>\n",
       "      <td>0.024797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.005790</td>\n",
       "      <td>0.006125</td>\n",
       "      <td>0.006385</td>\n",
       "      <td>0.006968</td>\n",
       "      <td>0.004761</td>\n",
       "      <td>0.007537</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>0.004126</td>\n",
       "      <td>0.000307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>poet</td>\n",
       "      <td>0.483051</td>\n",
       "      <td>-0.044163</td>\n",
       "      <td>0.009395</td>\n",
       "      <td>-0.007190</td>\n",
       "      <td>0.012207</td>\n",
       "      <td>0.006903</td>\n",
       "      <td>-0.006711</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>-0.000845</td>\n",
       "      <td>-0.001125</td>\n",
       "      <td>-0.000642</td>\n",
       "      <td>-0.000209</td>\n",
       "      <td>-0.000453</td>\n",
       "      <td>-0.000933</td>\n",
       "      <td>-0.000733</td>\n",
       "      <td>-0.000761</td>\n",
       "      <td>-0.000698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>personal_trainer</td>\n",
       "      <td>0.468293</td>\n",
       "      <td>-0.080944</td>\n",
       "      <td>-0.011850</td>\n",
       "      <td>-0.068043</td>\n",
       "      <td>0.032397</td>\n",
       "      <td>-0.028670</td>\n",
       "      <td>-0.037557</td>\n",
       "      <td>-0.091361</td>\n",
       "      <td>-0.049694</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000783</td>\n",
       "      <td>-0.000399</td>\n",
       "      <td>-0.001005</td>\n",
       "      <td>-0.000138</td>\n",
       "      <td>-0.000473</td>\n",
       "      <td>-0.000470</td>\n",
       "      <td>-0.000456</td>\n",
       "      <td>-0.000816</td>\n",
       "      <td>-0.000737</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>professor</td>\n",
       "      <td>0.452428</td>\n",
       "      <td>-0.018119</td>\n",
       "      <td>0.011301</td>\n",
       "      <td>-0.011141</td>\n",
       "      <td>-0.015243</td>\n",
       "      <td>-0.012384</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>-0.004640</td>\n",
       "      <td>-0.002251</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001640</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.001349</td>\n",
       "      <td>0.004071</td>\n",
       "      <td>-0.003034</td>\n",
       "      <td>-0.004298</td>\n",
       "      <td>-0.003673</td>\n",
       "      <td>-0.000717</td>\n",
       "      <td>-0.003564</td>\n",
       "      <td>-0.001995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>painter</td>\n",
       "      <td>0.452361</td>\n",
       "      <td>0.003161</td>\n",
       "      <td>0.036012</td>\n",
       "      <td>0.017337</td>\n",
       "      <td>-0.035538</td>\n",
       "      <td>0.012959</td>\n",
       "      <td>0.006991</td>\n",
       "      <td>-0.001613</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000951</td>\n",
       "      <td>-0.000336</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accountant</td>\n",
       "      <td>0.374554</td>\n",
       "      <td>-0.055930</td>\n",
       "      <td>-0.031311</td>\n",
       "      <td>-0.043805</td>\n",
       "      <td>-0.025312</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>-0.015143</td>\n",
       "      <td>-0.044432</td>\n",
       "      <td>-0.060287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>-0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attorney</td>\n",
       "      <td>0.367104</td>\n",
       "      <td>-0.035824</td>\n",
       "      <td>-0.003903</td>\n",
       "      <td>-0.007270</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.013928</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>-0.010897</td>\n",
       "      <td>-0.004719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>-0.001509</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>-0.001427</td>\n",
       "      <td>-0.001875</td>\n",
       "      <td>-0.002338</td>\n",
       "      <td>-0.002469</td>\n",
       "      <td>-0.001728</td>\n",
       "      <td>-0.000642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>photographer</td>\n",
       "      <td>0.356927</td>\n",
       "      <td>-0.052775</td>\n",
       "      <td>-0.011488</td>\n",
       "      <td>-0.036094</td>\n",
       "      <td>-0.004054</td>\n",
       "      <td>-0.017355</td>\n",
       "      <td>-0.004763</td>\n",
       "      <td>-0.035910</td>\n",
       "      <td>-0.031379</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>-0.000121</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>-0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dentist</td>\n",
       "      <td>0.345824</td>\n",
       "      <td>0.009651</td>\n",
       "      <td>-0.040738</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.013102</td>\n",
       "      <td>0.014166</td>\n",
       "      <td>0.008104</td>\n",
       "      <td>0.017242</td>\n",
       "      <td>0.015563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.000283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>filmmaker</td>\n",
       "      <td>0.322148</td>\n",
       "      <td>-0.005893</td>\n",
       "      <td>-0.023485</td>\n",
       "      <td>-0.017356</td>\n",
       "      <td>0.038690</td>\n",
       "      <td>0.032797</td>\n",
       "      <td>0.018358</td>\n",
       "      <td>-0.019507</td>\n",
       "      <td>-0.001827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.002261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chiropractor</td>\n",
       "      <td>0.298824</td>\n",
       "      <td>-0.025604</td>\n",
       "      <td>-0.004360</td>\n",
       "      <td>-0.073746</td>\n",
       "      <td>-0.023146</td>\n",
       "      <td>0.024071</td>\n",
       "      <td>-0.021350</td>\n",
       "      <td>-0.011547</td>\n",
       "      <td>-0.028457</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000152</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>0.000236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pastor</td>\n",
       "      <td>0.229282</td>\n",
       "      <td>-0.274172</td>\n",
       "      <td>-0.069785</td>\n",
       "      <td>-0.259533</td>\n",
       "      <td>-0.096731</td>\n",
       "      <td>-0.127909</td>\n",
       "      <td>-0.156583</td>\n",
       "      <td>-0.218206</td>\n",
       "      <td>-0.166127</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000073</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>architect</td>\n",
       "      <td>0.225399</td>\n",
       "      <td>0.053551</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>0.106769</td>\n",
       "      <td>0.110808</td>\n",
       "      <td>0.073486</td>\n",
       "      <td>-0.005593</td>\n",
       "      <td>0.049996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001115</td>\n",
       "      <td>0.004353</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>0.005941</td>\n",
       "      <td>0.002935</td>\n",
       "      <td>0.002423</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>-0.001770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comedian</td>\n",
       "      <td>0.219457</td>\n",
       "      <td>-0.225967</td>\n",
       "      <td>-0.081757</td>\n",
       "      <td>-0.156671</td>\n",
       "      <td>-0.065501</td>\n",
       "      <td>-0.076109</td>\n",
       "      <td>-0.087733</td>\n",
       "      <td>-0.118004</td>\n",
       "      <td>-0.124757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>-0.000133</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>0.000581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>software_engineer</td>\n",
       "      <td>0.157746</td>\n",
       "      <td>-0.065456</td>\n",
       "      <td>0.023591</td>\n",
       "      <td>-0.056956</td>\n",
       "      <td>-0.042324</td>\n",
       "      <td>-0.060300</td>\n",
       "      <td>-0.021202</td>\n",
       "      <td>0.015468</td>\n",
       "      <td>-0.036829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>0.009260</td>\n",
       "      <td>0.007132</td>\n",
       "      <td>0.006266</td>\n",
       "      <td>0.003512</td>\n",
       "      <td>0.006474</td>\n",
       "      <td>0.004885</td>\n",
       "      <td>0.004344</td>\n",
       "      <td>-0.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>surgeon</td>\n",
       "      <td>0.153592</td>\n",
       "      <td>-0.229816</td>\n",
       "      <td>-0.051839</td>\n",
       "      <td>-0.245461</td>\n",
       "      <td>-0.122859</td>\n",
       "      <td>-0.127233</td>\n",
       "      <td>-0.089205</td>\n",
       "      <td>-0.220015</td>\n",
       "      <td>-0.207968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>0.005888</td>\n",
       "      <td>0.004638</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.004059</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.003316</td>\n",
       "      <td>0.000101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>composer</td>\n",
       "      <td>0.153186</td>\n",
       "      <td>-0.068712</td>\n",
       "      <td>0.036272</td>\n",
       "      <td>-0.048370</td>\n",
       "      <td>-0.001737</td>\n",
       "      <td>-0.050061</td>\n",
       "      <td>-0.008452</td>\n",
       "      <td>-0.064452</td>\n",
       "      <td>-0.063849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.001463</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.001676</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.002464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dj</td>\n",
       "      <td>0.145299</td>\n",
       "      <td>-0.103824</td>\n",
       "      <td>0.099118</td>\n",
       "      <td>-0.145000</td>\n",
       "      <td>0.027647</td>\n",
       "      <td>-0.083824</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>-0.178824</td>\n",
       "      <td>-0.040588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>-0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>rapper</td>\n",
       "      <td>0.085859</td>\n",
       "      <td>-0.138772</td>\n",
       "      <td>0.047449</td>\n",
       "      <td>-0.096198</td>\n",
       "      <td>0.017225</td>\n",
       "      <td>0.030224</td>\n",
       "      <td>0.175496</td>\n",
       "      <td>0.019175</td>\n",
       "      <td>-0.012350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>-0.000048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label_profession  frac_female  debiased_biosbias_tpr_gender_gap  \\\n",
       "7           dietitian     0.920437                          0.290927   \n",
       "13              nurse     0.914502                          0.082735   \n",
       "15          paralegal     0.866109                          0.375755   \n",
       "27       yoga_teacher     0.858696                          0.276534   \n",
       "12              model     0.818988                          0.480652   \n",
       "10  interior_designer     0.782609                          0.182716   \n",
       "22       psychologist     0.620751                          0.000799   \n",
       "26            teacher     0.604382                          0.111221   \n",
       "11         journalist     0.492152                          0.019865   \n",
       "19          physician     0.491203                          0.019845   \n",
       "20               poet     0.483051                         -0.044163   \n",
       "17   personal_trainer     0.468293                         -0.080944   \n",
       "21          professor     0.452428                         -0.018119   \n",
       "14            painter     0.452361                          0.003161   \n",
       "0          accountant     0.374554                         -0.055930   \n",
       "2            attorney     0.367104                         -0.035824   \n",
       "18       photographer     0.356927                         -0.052775   \n",
       "6             dentist     0.345824                          0.009651   \n",
       "9           filmmaker     0.322148                         -0.005893   \n",
       "3        chiropractor     0.298824                         -0.025604   \n",
       "16             pastor     0.229282                         -0.274172   \n",
       "1           architect     0.225399                          0.053551   \n",
       "4            comedian     0.219457                         -0.225967   \n",
       "24  software_engineer     0.157746                         -0.065456   \n",
       "25            surgeon     0.153592                         -0.229816   \n",
       "5            composer     0.153186                         -0.068712   \n",
       "8                  dj     0.145299                         -0.103824   \n",
       "23             rapper     0.085859                         -0.138772   \n",
       "\n",
       "    very_scrubbed_tpr_gender_gap  debiased_tolga_tpr_gender_gap  \\\n",
       "7                       0.173878                       0.297707   \n",
       "13                      0.013742                       0.085377   \n",
       "15                      0.094656                       0.317482   \n",
       "27                      0.005518                       0.143784   \n",
       "12                      0.176120                       0.544309   \n",
       "10                     -0.013580                       0.243210   \n",
       "22                      0.008890                       0.045876   \n",
       "26                      0.025352                       0.129299   \n",
       "11                      0.010182                       0.057554   \n",
       "19                      0.036850                       0.056989   \n",
       "20                      0.009395                      -0.007190   \n",
       "17                     -0.011850                      -0.068043   \n",
       "21                      0.011301                      -0.011141   \n",
       "14                      0.036012                       0.017337   \n",
       "0                      -0.031311                      -0.043805   \n",
       "2                      -0.003903                      -0.007270   \n",
       "18                     -0.011488                      -0.036094   \n",
       "6                      -0.040738                       0.003124   \n",
       "9                      -0.023485                      -0.017356   \n",
       "3                      -0.004360                      -0.073746   \n",
       "16                     -0.069785                      -0.259533   \n",
       "1                       0.003069                       0.003208   \n",
       "4                      -0.081757                      -0.156671   \n",
       "24                      0.023591                      -0.056956   \n",
       "25                     -0.051839                      -0.245461   \n",
       "5                       0.036272                      -0.048370   \n",
       "8                       0.099118                      -0.145000   \n",
       "23                      0.047449                      -0.096198   \n",
       "\n",
       "    strong_debiased_1_tpr_gender_gap  strong_no_projection_tpr_gender_gap  \\\n",
       "7                           0.199900                             0.223862   \n",
       "13                          0.048740                             0.033271   \n",
       "15                          0.262077                             0.256944   \n",
       "27                          0.208049                             0.116196   \n",
       "12                          0.418456                             0.460211   \n",
       "10                          0.081481                             0.096296   \n",
       "22                          0.043524                             0.045169   \n",
       "26                          0.111760                             0.113756   \n",
       "11                          0.021920                             0.001790   \n",
       "19                          0.035120                             0.042554   \n",
       "20                          0.012207                             0.006903   \n",
       "17                          0.032397                            -0.028670   \n",
       "21                         -0.015243                            -0.012384   \n",
       "14                         -0.035538                             0.012959   \n",
       "0                          -0.025312                             0.000459   \n",
       "2                           0.007254                             0.013928   \n",
       "18                         -0.004054                            -0.017355   \n",
       "6                           0.013102                             0.014166   \n",
       "9                           0.038690                             0.032797   \n",
       "3                          -0.023146                             0.024071   \n",
       "16                         -0.096731                            -0.127909   \n",
       "1                           0.106769                             0.110808   \n",
       "4                          -0.065501                            -0.076109   \n",
       "24                         -0.042324                            -0.060300   \n",
       "25                         -0.122859                            -0.127233   \n",
       "5                          -0.001737                            -0.050061   \n",
       "8                           0.027647                            -0.083824   \n",
       "23                          0.017225                             0.030224   \n",
       "\n",
       "    strong_debiased_2_tpr_gender_gap  strong_no_equalize_tpr_gender_gap  \\\n",
       "7                           0.187072                           0.250980   \n",
       "13                          0.025981                           0.057404   \n",
       "15                          0.271437                           0.314915   \n",
       "27                          0.195067                           0.161636   \n",
       "12                          0.455824                           0.532551   \n",
       "10                          0.041975                           0.224691   \n",
       "22                          0.020219                           0.042056   \n",
       "26                          0.114246                           0.119168   \n",
       "11                          0.013070                           0.042923   \n",
       "19                          0.040719                           0.034896   \n",
       "20                         -0.006711                           0.016393   \n",
       "17                         -0.037557                          -0.091361   \n",
       "21                          0.002382                          -0.004640   \n",
       "14                          0.006991                          -0.001613   \n",
       "0                          -0.015143                          -0.044432   \n",
       "2                           0.004176                          -0.010897   \n",
       "18                         -0.004763                          -0.035910   \n",
       "6                           0.008104                           0.017242   \n",
       "9                           0.018358                          -0.019507   \n",
       "3                          -0.021350                          -0.011547   \n",
       "16                         -0.156583                          -0.218206   \n",
       "1                           0.073486                          -0.005593   \n",
       "4                          -0.087733                          -0.118004   \n",
       "24                         -0.021202                           0.015468   \n",
       "25                         -0.089205                          -0.220015   \n",
       "5                          -0.008452                          -0.064452   \n",
       "8                           0.000882                          -0.178824   \n",
       "23                          0.175496                           0.019175   \n",
       "\n",
       "    glove_tpr_gender_gap           ...             \\\n",
       "7               0.232835           ...              \n",
       "13              0.082411           ...              \n",
       "15              0.271437           ...              \n",
       "27              0.208374           ...              \n",
       "12              0.505093           ...              \n",
       "10              0.270370           ...              \n",
       "22              0.017593           ...              \n",
       "26              0.137121           ...              \n",
       "11              0.058686           ...              \n",
       "19              0.024797           ...              \n",
       "20              0.001949           ...              \n",
       "17             -0.049694           ...              \n",
       "21             -0.002251           ...              \n",
       "14             -0.002095           ...              \n",
       "0              -0.060287           ...              \n",
       "2              -0.004719           ...              \n",
       "18             -0.031379           ...              \n",
       "6               0.015563           ...              \n",
       "9              -0.001827           ...              \n",
       "3              -0.028457           ...              \n",
       "16             -0.166127           ...              \n",
       "1               0.049996           ...              \n",
       "4              -0.124757           ...              \n",
       "24             -0.036829           ...              \n",
       "25             -0.207968           ...              \n",
       "5              -0.063849           ...              \n",
       "8              -0.040588           ...              \n",
       "23             -0.012350           ...              \n",
       "\n",
       "    very_scrubbed_tnr_gender_gap  debiased_tolga_tnr_gender_gap  \\\n",
       "7                      -0.000674                      -0.002692   \n",
       "13                     -0.001686                      -0.007627   \n",
       "15                      0.000247                      -0.000103   \n",
       "27                      0.000535                      -0.001455   \n",
       "12                     -0.001022                      -0.000566   \n",
       "10                      0.000226                      -0.000884   \n",
       "22                     -0.000742                      -0.005913   \n",
       "26                     -0.000813                      -0.004694   \n",
       "11                      0.000762                      -0.000167   \n",
       "19                      0.001413                       0.005790   \n",
       "20                      0.000827                      -0.000845   \n",
       "17                     -0.000783                      -0.000399   \n",
       "21                     -0.001640                       0.001259   \n",
       "14                     -0.000951                      -0.000336   \n",
       "0                       0.001341                       0.000090   \n",
       "2                       0.003337                      -0.000622   \n",
       "18                      0.001568                       0.000615   \n",
       "6                       0.000945                       0.000738   \n",
       "9                       0.000127                       0.002068   \n",
       "3                      -0.000152                       0.000921   \n",
       "16                     -0.000073                       0.001051   \n",
       "1                      -0.001115                       0.004353   \n",
       "4                       0.000234                       0.000593   \n",
       "24                      0.001209                       0.005100   \n",
       "25                      0.002435                       0.005888   \n",
       "5                       0.001154                       0.001802   \n",
       "8                       0.000244                       0.001133   \n",
       "23                      0.000577                       0.000155   \n",
       "\n",
       "    strong_debiased_1_tnr_gender_gap  strong_no_projection_tnr_gender_gap  \\\n",
       "7                          -0.001220                            -0.001617   \n",
       "13                         -0.007427                            -0.004478   \n",
       "15                          0.000095                            -0.000012   \n",
       "27                         -0.001289                            -0.000758   \n",
       "12                          0.000379                             0.000429   \n",
       "10                          0.000032                            -0.000023   \n",
       "22                         -0.004535                            -0.002672   \n",
       "26                         -0.002497                            -0.004570   \n",
       "11                          0.001286                             0.001514   \n",
       "19                          0.006125                             0.006385   \n",
       "20                         -0.001125                            -0.000642   \n",
       "17                         -0.001005                            -0.000138   \n",
       "21                          0.001349                             0.004071   \n",
       "14                         -0.000125                            -0.000197   \n",
       "0                           0.000390                             0.000694   \n",
       "2                          -0.001509                            -0.001953   \n",
       "18                         -0.000121                            -0.000051   \n",
       "6                           0.000532                             0.000574   \n",
       "9                           0.001236                             0.001535   \n",
       "3                           0.000345                             0.000175   \n",
       "16                          0.000741                             0.000602   \n",
       "1                           0.001076                             0.001065   \n",
       "4                          -0.000030                             0.000366   \n",
       "24                          0.009260                             0.007132   \n",
       "25                          0.004638                             0.002488   \n",
       "5                           0.001463                             0.001543   \n",
       "8                           0.000257                             0.000211   \n",
       "23                          0.000631                             0.000491   \n",
       "\n",
       "    strong_debiased_2_tnr_gender_gap  strong_no_equalize_tnr_gender_gap  \\\n",
       "7                          -0.001530                          -0.002213   \n",
       "13                         -0.004807                          -0.004455   \n",
       "15                          0.000075                          -0.000219   \n",
       "27                         -0.001393                          -0.001211   \n",
       "12                         -0.000039                          -0.000513   \n",
       "10                          0.000024                          -0.000676   \n",
       "22                         -0.002096                          -0.004275   \n",
       "26                         -0.001141                          -0.002609   \n",
       "11                          0.001955                           0.000651   \n",
       "19                          0.006968                           0.004761   \n",
       "20                         -0.000209                          -0.000453   \n",
       "17                         -0.000473                          -0.000470   \n",
       "21                         -0.003034                          -0.004298   \n",
       "14                          0.000173                           0.000315   \n",
       "0                           0.000483                           0.000683   \n",
       "2                          -0.001427                          -0.001875   \n",
       "18                         -0.000025                           0.001542   \n",
       "6                           0.000563                           0.000409   \n",
       "9                           0.001641                           0.001847   \n",
       "3                           0.000617                           0.000419   \n",
       "16                          0.000453                           0.001137   \n",
       "1                           0.002815                           0.005941   \n",
       "4                          -0.000133                           0.000633   \n",
       "24                          0.006266                           0.003512   \n",
       "25                          0.002320                           0.004059   \n",
       "5                           0.001389                           0.001676   \n",
       "8                           0.000721                           0.000564   \n",
       "23                          0.000268                           0.000834   \n",
       "\n",
       "    glove_tnr_gender_gap  strong_debiased_4_tnr_gender_gap  \\\n",
       "7              -0.002810                         -0.001630   \n",
       "13             -0.005866                         -0.002840   \n",
       "15             -0.000164                         -0.000060   \n",
       "27             -0.001211                         -0.001081   \n",
       "12             -0.001008                          0.000249   \n",
       "10             -0.000201                          0.000216   \n",
       "22             -0.002278                         -0.003760   \n",
       "26             -0.002664                         -0.002461   \n",
       "11              0.000014                          0.001617   \n",
       "19              0.007537                          0.001844   \n",
       "20             -0.000933                         -0.000733   \n",
       "17             -0.000456                         -0.000816   \n",
       "21             -0.003673                         -0.000717   \n",
       "14             -0.000022                         -0.000223   \n",
       "0               0.000757                          0.000344   \n",
       "2              -0.002338                         -0.002469   \n",
       "18              0.001537                         -0.000092   \n",
       "6               0.000801                          0.000516   \n",
       "9               0.002094                          0.001204   \n",
       "3               0.000127                          0.000096   \n",
       "16              0.001293                          0.000333   \n",
       "1               0.002935                          0.002423   \n",
       "4               0.000753                          0.000327   \n",
       "24              0.006474                          0.004885   \n",
       "25              0.005013                          0.003432   \n",
       "5               0.001567                          0.001011   \n",
       "8               0.000206                          0.000826   \n",
       "23              0.001200                          0.000645   \n",
       "\n",
       "    strong_debiased_3_tnr_gender_gap  scrubbed_tnr_gender_gap  \n",
       "7                          -0.001412                -0.000266  \n",
       "13                         -0.002707                -0.001573  \n",
       "15                         -0.000236                 0.000195  \n",
       "27                         -0.001399                 0.000299  \n",
       "12                          0.000181                 0.001161  \n",
       "10                         -0.000013                 0.000407  \n",
       "22                         -0.002820                -0.001450  \n",
       "26                         -0.001785                 0.000671  \n",
       "11                          0.001571                -0.002623  \n",
       "19                          0.004126                 0.000307  \n",
       "20                         -0.000761                -0.000698  \n",
       "17                         -0.000737                 0.000032  \n",
       "21                         -0.003564                -0.001995  \n",
       "14                          0.000050                 0.000144  \n",
       "0                           0.000355                -0.000109  \n",
       "2                          -0.001728                -0.000642  \n",
       "18                          0.000170                -0.000297  \n",
       "6                           0.000359                 0.000283  \n",
       "9                           0.000814                 0.002261  \n",
       "3                           0.000309                 0.000236  \n",
       "16                          0.000333                 0.000199  \n",
       "1                           0.003652                -0.001770  \n",
       "4                          -0.000055                 0.000581  \n",
       "24                          0.004344                -0.000074  \n",
       "25                          0.003316                 0.000101  \n",
       "5                           0.001245                 0.002464  \n",
       "8                           0.000299                -0.000025  \n",
       "23                          0.000180                -0.000048  \n",
       "\n",
       "[28 rows x 24 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_gap_df.sort_values('frac_female', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraction of comments where new model has lower\n",
    "# TPR gap than the baseline\n",
    "\n",
    "def compute_fraction_improved(df, baseline_model, improved_model):\n",
    "    is_improved = np.abs(df[baseline_model]) >= np.abs(df[improved_model])\n",
    "    return np.mean(is_improved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debiased_biosbias\n",
      "0.32142857142857145\n",
      "very_scrubbed\n",
      "0.7142857142857143\n",
      "debiased_tolga\n",
      "0.2857142857142857\n",
      "strong_debiased_1\n",
      "0.6428571428571429\n",
      "strong_no_projection\n",
      "0.6071428571428571\n",
      "strong_debiased_2\n",
      "0.7142857142857143\n",
      "strong_no_equalize\n",
      "0.39285714285714285\n",
      "glove\n",
      "1.0\n",
      "strong_debiased_4\n",
      "0.6071428571428571\n",
      "strong_debiased_3\n",
      "0.6071428571428571\n",
      "scrubbed\n",
      "0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "for _model in MODEL_NAMES.values():\n",
    "    print(_model)\n",
    "    print(compute_fraction_improved(gender_gap_df, 'glove_tpr_gender_gap', '{}_tpr_gender_gap'.format(_model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_cols = ['{}_tpr_gender_gap'.format(_model) for _model in MODEL_NAMES.values()]\n",
    "tnr_cols = ['{}_tnr_gender_gap'.format(_model) for _model in MODEL_NAMES.values()]\n",
    "gender_gap_cols = tpr_cols + tnr_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "debiased_biosbias_tpr_gender_gap       0.029446\n",
       "very_scrubbed_tpr_gender_gap           0.003786\n",
       "debiased_tolga_tpr_gender_gap          0.028584\n",
       "strong_debiased_1_tpr_gender_gap       0.014313\n",
       "strong_no_projection_tpr_gender_gap    0.015602\n",
       "strong_debiased_2_tpr_gender_gap       0.016134\n",
       "strong_no_equalize_tpr_gender_gap      0.025152\n",
       "glove_tpr_gender_gap                   0.022636\n",
       "strong_debiased_4_tpr_gender_gap       0.016461\n",
       "strong_debiased_3_tpr_gender_gap       0.014632\n",
       "scrubbed_tpr_gender_gap                0.000189\n",
       "debiased_biosbias_tnr_gender_gap       0.000011\n",
       "very_scrubbed_tnr_gender_gap           0.000001\n",
       "debiased_tolga_tnr_gender_gap          0.000009\n",
       "strong_debiased_1_tnr_gender_gap       0.000009\n",
       "strong_no_projection_tnr_gender_gap    0.000006\n",
       "strong_debiased_2_tnr_gender_gap       0.000006\n",
       "strong_no_equalize_tnr_gender_gap      0.000006\n",
       "glove_tnr_gender_gap                   0.000008\n",
       "strong_debiased_4_tnr_gender_gap       0.000003\n",
       "strong_debiased_3_tnr_gender_gap       0.000004\n",
       "scrubbed_tnr_gender_gap                0.000001\n",
       "dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_gap_df[gender_gap_cols].apply(lambda x: np.mean(x**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "debiased_biosbias_tpr_gender_gap       0.119049\n",
       "very_scrubbed_tpr_gender_gap           0.041268\n",
       "debiased_tolga_tpr_gender_gap          0.114932\n",
       "strong_debiased_1_tpr_gender_gap       0.075670\n",
       "strong_no_projection_tpr_gender_gap    0.079293\n",
       "strong_debiased_2_tpr_gender_gap       0.075149\n",
       "strong_no_equalize_tpr_gender_gap      0.102661\n",
       "glove_tpr_gender_gap                   0.096764\n",
       "strong_debiased_4_tpr_gender_gap       0.083171\n",
       "strong_debiased_3_tpr_gender_gap       0.070882\n",
       "scrubbed_tpr_gender_gap                0.007773\n",
       "debiased_biosbias_tnr_gender_gap       0.002204\n",
       "very_scrubbed_tnr_gender_gap           0.000958\n",
       "debiased_tolga_tnr_gender_gap          0.002066\n",
       "strong_debiased_1_tnr_gender_gap       0.001811\n",
       "strong_no_projection_tnr_gender_gap    0.001657\n",
       "strong_debiased_2_tnr_gender_gap       0.001537\n",
       "strong_no_equalize_tnr_gender_gap      0.001866\n",
       "glove_tnr_gender_gap                   0.001997\n",
       "strong_debiased_4_tnr_gender_gap       0.001316\n",
       "strong_debiased_3_tnr_gender_gap       0.001376\n",
       "scrubbed_tnr_gender_gap                0.000747\n",
       "dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_gap_df[gender_gap_cols].apply(lambda x: np.mean(np.abs(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tpr_gap(df, _model):\n",
    "    fig, ax = plt.subplots(figsize=(15, 6))\n",
    "    x = 'frac_female'\n",
    "    y = '{}_tpr_gender_gap'.format(_model)\n",
    "    p1 = sns.regplot(x = x, y = y, data = df)\n",
    "    p1.set(xlabel = \"% Female\", ylabel = \"TPR Gender Gap\", title = _model)\n",
    "\n",
    "    for line in range(0,df.shape[0]):\n",
    "         p1.text(results_df[x][line]+0.01, df[y][line], df['label_profession'][line], horizontalalignment='left', size='medium', color='black')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _model in MODEL_NAMES.values():\n",
    "    if 'untuned' in _model:\n",
    "        plot_tpr_gap(results_df, _model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frac_female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>frac_female</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debiased_biosbias_tpr_gender_gap</th>\n",
       "      <td>0.829982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>very_scrubbed_tpr_gender_gap</th>\n",
       "      <td>0.458378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debiased_tolga_tpr_gender_gap</th>\n",
       "      <td>0.824882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strong_debiased_1_tpr_gender_gap</th>\n",
       "      <td>0.716922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strong_no_projection_tpr_gender_gap</th>\n",
       "      <td>0.709000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strong_debiased_2_tpr_gender_gap</th>\n",
       "      <td>0.596896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strong_no_equalize_tpr_gender_gap</th>\n",
       "      <td>0.772645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glove_tpr_gender_gap</th>\n",
       "      <td>0.794059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strong_debiased_4_tpr_gender_gap</th>\n",
       "      <td>0.550435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strong_debiased_3_tpr_gender_gap</th>\n",
       "      <td>0.707174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scrubbed_tpr_gender_gap</th>\n",
       "      <td>-0.282919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     frac_female\n",
       "frac_female                             1.000000\n",
       "debiased_biosbias_tpr_gender_gap        0.829982\n",
       "very_scrubbed_tpr_gender_gap            0.458378\n",
       "debiased_tolga_tpr_gender_gap           0.824882\n",
       "strong_debiased_1_tpr_gender_gap        0.716922\n",
       "strong_no_projection_tpr_gender_gap     0.709000\n",
       "strong_debiased_2_tpr_gender_gap        0.596896\n",
       "strong_no_equalize_tpr_gender_gap       0.772645\n",
       "glove_tpr_gender_gap                    0.794059\n",
       "strong_debiased_4_tpr_gender_gap        0.550435\n",
       "strong_debiased_3_tpr_gender_gap        0.707174\n",
       "scrubbed_tpr_gender_gap                -0.282919"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[['frac_female']+['{}_tpr_gender_gap'.format(_model) for _model in MODEL_NAMES.values()]].corr()[['frac_female']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which model does this correspond to?\n",
    "model_name = 'tf_gru_attention_multiclass_gender_biosbias_glove:v_20190405_142640'\n",
    "gender_df['correct'] = ((gender_df['gender'] == 'M') == gender_df[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8423\n"
     ]
    }
   ],
   "source": [
    "acc = gender_df.correct.sum()/gender_df.correct.count()\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "models_eval_py2",
   "language": "python",
   "name": "models_eval_py2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
